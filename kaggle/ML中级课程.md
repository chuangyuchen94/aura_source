### 课程链接 
- https://www.kaggle.com/code/alexisbcook/introduction

### 1. 简介
- 提升的地方
  - 处理真实数据时可能遇到的各种问题，如，数据缺失
  - 设计pipelines来提升机器学习代码的指令
  - 使用更高级的验证模型技术，如，交叉验证（cross-validation）
  - 构建新的模型--当下最好的模型（state-of-the-art model）
  - 避免常见且重要的数据科学错误，如，泄露（leakage）

### 2. 缺失值的处理
- 很多机器学习的库，遇到缺失的值时，在构建模型时会报错
- 3个措施
  - 方案1：把整列都去掉（不建议，容易错失重要数据）
    - 直接调用数据集的drop方法
  - 方案2：进行值的填充
    - 比如，用其他非缺失值的平均值来填充
    - 更加复杂的策略，并不一定能带来额外的收获
    - 代码
      - from sklearn.impute import SimpleImputer
      - imputer = SimpleImputer()
      - 对训练集填充：imputer.fit_transform(X_train)
      - 对测试集填充：imputer.transform(x_test)
    - 注意
      - 训练时使用的SimpleImputer，会记录特征名称，因此，验证数据必须包含完全相同的列名和顺序
      - 经过SimpleImputer预处理后的数据，为numpy数组，再转换为DataFrame时，会丢失columns，此时，需要手工恢复列名
        - final_X_train = pandas.DataFrame(imputer.fit_transform(X_train))
        - final_X_train.columns = X_train.columns
  - 方案3：对填充的扩展
    - 增加一列，标识哪些行的数据原先是缺失的

### 3. 分类变量（categorical variable）
- 什么是分类变量：只有有限个数的值的变量
- 对分类变量，要先做预处理
  - 不然，直接给到模型处理，很多模型会直接报错
- 3个策略（通常情况下，独热编码最优）
  - 策略1：直接把分类变量干掉，不要了
    - 代码示例
      - X_train.select_dtypes(exclude=["object"]) # 把非数字的列排除掉
  - 策略2：序数编码（Ordinal Encoding）
    - 把选项映射成有序的枚举值，枚举值之间可以排序
    - 代码示例
      - from sklearn.preprocessing import OrdinalEncoder
      - ordinal_encoder = OrdinalEncoder()
      - s = (X_train.dtypes == "object")
      - object_cols = list(s[s].index)
      - label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])
      - label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])
  - 策略3：独热编码（One-Hot Encoding）
    - 对每个枚举值单独创建一列，值为0或1，其中，1表示该行数据取得该枚举值
    - 优点：对枚举值的排序没有要求
    - 缺点：枚举值太多，会影响模型性能
    - 代码示例
      - from sklearn.preprocessing import OneHotEncoder
      - one_hot_encoder = OneHotEncoder(handle_unknown="ignore", sparse=False)
        - 参数说明：
          - handle_unknown="ignore" ：当验证数据（测试数据）中的枚举值，在训练集中不存在时，忽略该枚举值
          - sparse=False ：返回numpy数组，而不是稀疏矩阵
      - one_handle_train_cols = pd.DataFrame(one_hot_encoder.fit_transform(X_train[object_cols]))
      - one_handle_valid_cols = pd.DataFrame(one_hot_encoder.transform(X_valid[object_cols]))
      - 独热编码会生成新的RangeIndex，需要将其恢复为原来的索引
        - one_handle_train_cols.index = X_train.index
        - one_handle_valid_cols.index = X_valid.index
      - num_X_train = X_train.drop(object_cols, axis=1) : 保留数字列
      - num_X_valid = X_valid.drop(object_cols, axis=1) ：保留数字列
      - 将数字列与独热编码后的列进行合并：
        - one_handle_X_train = pd.concat([one_handle_train_cols, num_X_train], axis=1)
        - one_handle_X_valid = pd.concat([one_handle_valid_cols, num_X_valid], axis=1)
      - 对数据进行进一步处理：列名统一为字符串（因为经过OneHotEncoder处理后，列名会变成数字）
        - one_handle_X_train.columns = one_handle_X_train.columns.astype(str)
        - one_handle_X_valid.columns = one_handle_X_valid.columns.astype(str)

### 4. pipelines(流水线)
- 定义：用预处理技术对复杂模型进行部署及测试
- 作用：优化建模代码
  - 更好的组织代码，包括：预处理，建模，将这些步骤捆绑在一起，使得像是一个步骤
- 构建流水线
  - 第1步：定义预处理的步骤
    - ColumnTransformer类：用以捆绑不同的预处理步骤
      - 每个元组定义一组处理：(名称, 转换器, 列名或列索引)
      - 参数说明
        - transformer: 转换器列表
        - remainder: 对未选中的列的处理方式，'passthrough'（保留），'drop'（丢弃）
      - 例如：
        - 填充缺失的数值型数据
        - 填充缺失的分类型数据，并进行独热编码（one hot encode）
    - Pipeline类
      - 通过steps参数定义流水线步骤，每个步骤是一个元组(name, transformer/estimator) ==》 (步骤名称, 转换器或模型)
      - 将多个数据处理步骤和机器学习模型串联起来，形成一个工作流
      - 每一步的输出是下一步的输入
    - 代码示例
      - from sklearn.compose import ColumnTransformer
      - from sklearn.pipeline import Pipeline
      - numerical_transformer = SimpleImputer(strategy="constant")
      - categorical_transformer = Pipeline(steps=[
        - ("imputer", SimpleImputer(strategy="most_frequent")),
        - ("onebot", OneHotEncoder(handle_unknown="ignore"))
      - ])
      - preprocessor = ColumnTransformer(
        - transformers = [
          ("num", numerical_transformer, numerical_cols),
        - ("cat", categorical_transformer, categorical_cols)
        - ]
        - )
  - 第2步：定义模型
  - 第3步：创建并评估流水线
    - 用Pipeline类来定义流水线：打包预处理和模型化步骤

### 5. 交叉验证（cross validation）
- 目的：更好的验证模型的性能
  - 进而不需要再去手工划分测试数据集和验证数据集
- 机器学习：是一个迭代的过程
- 验证数据与测试数据的数据量的平衡
  - 验证数据集越大，对模型质量的测量，就越少随机性；
  - 测试数据集越大，模型的指令也越好
  - 因此，如何更好的切分验证数据集与测试数据集
- 什么是交叉验证
  - 定义：用不同的数据子集，执行建模的流程，以获得对模型质量的多重测量
  - 举例：将数据分为5份
    - 第1次，用第1份数据作为验证数据，其他数据作为训练数据
    - 第2次，用第2份数据作为验证数据，其他数据作为训练数据
    - 第3次，用第3份数据作为验证数据，其他数据作为训练数据
    - 第4次，用第4份数据作为验证数据，其他数据作为训练数据
    - 第5次，用第5份数据作为验证数据，其他数据作为训练数据
    - 通过这样的过程，就把所有的数据都作为验证数据执行了一遍
  - 什么时候用交叉验证
    - 如果你的模型仅需要花费几分钟来执行，那么值得使用交叉验证
- 注意事项：
  - 需要结合pipeline：虽然可以不用pipeline来做交叉验证，但会增加难度
- 代码示例
  - from sklearn.model_selection import cross_val_score
  - scores = -1 * cross_val_score(estimator=my_pipeline, X, y, cv=5, scoring="neg_mean_absolute_error"")
    - estimator: 实现了fit和predict的模型对象
    - cv: 来设置数据以多少份来分
    - scoring: 评估指标名称或函数，如，"accuracy"、"neg_mean_absolute_error"、"neg_mean_squared_error"

### 6. XGBoost
- XGBoost：对于结构化数据的最精准的建模技术
- 用梯度提升（gradient boosting）的方法，来创建并优化模型
- 集成方法（ensemble method）：组合了多种模型的预测
  - 例如，随机森林，梯度提升
- 梯度提升
  - 定义：一种循环迭代的将模型加入到集成中的方法
  - 过程
    - 从初始化集成开始：加入一个模型
    - 开始循环
      - 用当前的集成，来生成预测
      - 用损失函数（loss function）来运算预测值
      - 用损失函数来训练新的模型，然后将其加入到集成中
        - 特别的，通过调整模型的参数，来降低损失
      - 重复以上步骤
  - XGBoost库: xgboost
  - 代码示例
    - from xgboost import XGBRegressor
    - my_model = XGBRegressor()
    - my_model.fit(X_train, y_train)
    - my_model.predict(X_valid)
  - 参数调优
    - `n_estimators`: 指定执行多少次建模循环，等同于集成中的模型数量
      - 太低，容易导致欠拟合；
      - 太高，容易导致过拟合
      - 典型的值：100~1000，且依赖于learning_rate参数
    - `early_stopping_rounds`: 提供一种方法，以自动的找到n_estimators的理想值
      - 当验证的分数恶化时，early_stopping_rounds指定了，在连续出现多少次验证得分不再提升时，停止迭代
      - 通常来说，设定高的n_estimators，然后用early_stopping_rounds来找到最优n_estimators
    - 代码示例
      - my_model = XGBRegressor(n_estimators=1000, early_stopping_rounds=5)
    - `learning_rate`: 在将每个模型的预测相加前，先用learning_rate进行乘积
      - 默认情况下，XGBoost将learning_rate设置为0.1
    - 代码示例
      - my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)
    - `n_jobs`: 指定并发任务数，用以更快的构建模型
      - 通常情况下，将n_jobs设置为机器的核心数
    - 代码示例
      - my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)

### 7. 数据泄露（Data Leakage）
- 定义：因为意外或错误，在训练时，让模型接触到了未来信息或测试集的信息，导致模型的测试结果偏高，而实际预测时，结果就不准确
- 有两种类型的泄露
  - target leakage(目标泄露)
    - 特征列中，包含了与目标值直接相关的信息
  - train-test contamination(训练-测试污染)