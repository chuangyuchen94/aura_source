- 离散数据
  - $P(A)=\frac{n}{N}$
  - 数个数
  - 数据集中，某一类样本的先验概率

- 连续数据
  - $P(x_0)=\int_{x_{0^-}}^{x_0^+}{f(x)dx}=0$
  - $P(x_0) \to f(x_0)$
  - $f(x) = \frac{1}{\sqrt{2\pi\sigma}}{e^{-\frac{(x-\mu)^2}{2\sigma^2}}}$

- 独立
  - $P(AB)=P(A)P(B)$ -- P(AB): A和B同时发生的概率
  - 在机器学习中，特征都是相互独立的

- 条件概率
  - A和B任意情况：$P(B|A)=\frac{P(AB)}{P(A)}$ -- 在A发生的条件下，B发生的概率
  - A和B互相独立：$P(B)=\frac{P(AB)}{P(A)}$
  - 求解方法：切分数据集
  - $P(B|A)=\frac{P(AB)}{P(A)}$
  - $P(A|B)=\frac{P(AB)}{P(B)}$
  - $P(A)P(B|A)=P(B)P(A|B)$
  - $P(B|A)=\frac{P(B)P(A|B)}{P(A)}$
  - $P(y|X)=\frac{P(y)P(X|y)}{P(X)}$ -- 对应了模型的内涵，X是输入，y是输出
    - $P(y_0|X_i)=\frac{P(y_0)P(X_i|y_0)}{P(X_i)}$
    - $P(y_1|X_i)=\frac{P(y_1)P(X_i|y_1)}{P(X_i)}$
    - $P(y_2|X_i)=\frac{P(y_2)P(X_i|y_2)}{P(X_i)}$
    - 从3个结果中，取概率最大的一个
  - 代码
    - from sklearn.naive_bayes import GaussianNB

### 朴素贝叶斯的前提假设
- 连续型变量的概率 $\to$ 概率密度函数的值
- 一个未知的连续型分布 $\to$ 看作高斯分布
- 把每个特征看作条件独立