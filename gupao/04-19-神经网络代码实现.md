### 1. 算法的实现
- 第1步：初始化参数
  - 层数：神经元的层数
  - 权重参数：初始化（需要考虑偏置项）
  - 最大迭代次数
  - 学习率
- 第2步：数据预处理
  - 标准化
- 第3步：训练数据
  - 梯度下降：实现前向传播、反向传播
    - 计算当前的损失值
    - 计算当前的梯度值
    - 更新参数值
  - 损失函数：计算损失值
    - 前向传播得到最终结果，
    - 与真实值相比，计算损失值
  - 计算梯度值
    - 反向传播，
    - 每一层对结果的影响
    - 计算梯度值

### 2. 总结
- 前向传播、在计算损失值之前，是不知道最终结果的，即，训练的标签值，只会在计算损失值时用到，在训练、前向传播的过程中，并没有用到
- 前向传播结束后，计算得到损失值及梯度值，梯度值用于反向逐层更新参数
  - 输入层到第1层隐藏层：线性变换、sigmoid转换
  - 第1层隐藏层到输出层：线性变换、softmax计算概率值
  - 这种情况下，前向传播的梯度值如何计算，反向传播该如何做
- 