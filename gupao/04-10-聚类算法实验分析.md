### 1. K-MEANS与DBSCAN算法
- 构造数据集
  - 工具：sklearn.datasets.make_blobs # 构建数据
- K-MEANS类
  - 工具：sklearn.cluster.KMeans # K-MEANS算法
  - 参数：
    - n_cluster：簇的个数
    - init：初始质心的方法
    - n_init: 运行初始质心方法的次数，并取最优
    - max_iter: 最大迭代次数
  - 方法
    - fit(X): 训练模型
    - fit_predict(X)：训练模型，并返回每个数据样本的聚类标签
    - transform(X)：计算X中每个样本到质心的距离
- 算法流程：K-MEANS每走一步，是什么样子 
- 不稳定的结果
  - 初始质心对结果的影响较大
- 评估标准
  - sklearn.cluster.KMeans的属性：`inertia_` -- 所有样本到其最近的质心的欧式距离之和
- 找到`最佳簇数`：找拐点
  - 随着k值的增大，评估值会越来越低
    - 找到拐点：在拐点之后，评估值的下降趋势变得不明显
- K-MEANS存在的问题
  - 评估指标的值小，并不一定就意味着分类的结果正确：评估指标只能用来参考
- 另外一个评估标准：`轮廓系数`
  - 由两个值组成：
    - $ai$ - 样本i的簇内不相似度：每个样本到其所属簇的其他样本的平均距离。
    - $bi$ - 样本i的簇间不相似度：每个样本到其他某簇$C_j$的所有样本的平均距离$b_{ij}$。$b_i=min{bi_{i1}, b_{i2}, ..., b_{ik}}$
  - $s_i = \frac{b_i - a_i}{max(a_i, b_i)}$
    - $s_i$越接近1，则说明样本i的聚类合理
    - $s_i$越接近-1，则说明样本i更应该分类到另外的簇
    - $s_i$近似为0，则说明样本i的在两个簇的边界上
  - 工具包：sklearn.metrics.silhouette_score
- 图像分隔小例子
  - K-MEANS的数据集的维度：2维

### 2. 半监督问题解决方案

### 3. 聚类评估方法
