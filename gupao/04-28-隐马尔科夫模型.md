### 1. 隐马尔科夫模型HMM
- 定义
- 隐马尔科夫模型
  - 一种用于处理`序列数据`的概率模型；
  - 适用于隐藏状态不可直接观测，但可通过观测状态间接推断的场景
- 序列数据
  - 数据点按时间、空间或其他逻辑顺序排列，且顺序不可随意调换，其中，数据之间的顺序关系包含重要信息
  - 特点
    - 有序性：有先后顺序，且不可随意调换
    - 依赖性：当前的数据点，可能依赖于前序或后序数据
    - 动态性：数据随着时间
  - 常见类型
    - 时间序列
    - 空间序列
    - 文本序列
    - 状态序列

### 2. 基本概念
- 隐藏状态：不可直接观测的状态
- 观测状态：可观测的、与隐藏状态相关的数据
- 两个独立性假设
  - 马尔科夫性：当前隐藏状态，仅依赖于前一状态，即，$P(z_t|z_{t-1})$；
  - 观测独立性：当前观测仅依赖当前隐藏状态，即，$P(x_t|z_t)$

### 3. 模型组成
- 初始概率分布 $π$：初始时刻，各隐藏状态的概率；
- 状态转移矩阵 $A$：描述状态间的转移概率；
- 观察概率矩阵 $B$：隐藏状态生成观察状态的概率

### 4. 三大核心问题
- 评估问题
  - 目标：计算给定模型及观测序列，观测序列的概率 $P(O|\lambda)$；求解（隐藏）状态序列，使得$P(O|\lambda)$最大
    - 模型：$\lambda$ = ($\pi$, $A$, $B$)
    - 观测序列：$O = \{o_1, o_2, ..., 0_T\}$
      - 每个 $o_t$ 表示时刻 $t$ 的观测值
    - 隐藏状态序列：$I = \{i_1, i_2, ..., i_T\}$
      - 每个 $i_t$ 表示时刻 $t$ 的隐藏状态
  - 算法：前向算法（动态规划）
    - 通过递推，计算每个时刻的“前向概率”
- 学习问题
  - 目标：从观测序列中，学习模型参数（$\pi$、$A$、$B$）
  - 算法：Baum-Welch算法，通过迭代优化参数最大化 $P(O|\lambda)$
  - 步骤：E步计算期望，M步更新参数
- 解码问题
  - 找到最可能的隐藏状态序列
  - 算法：维特比算法（动态规划），记录每个时刻、每个状态的的最大概率路径，回溯得到最优序列