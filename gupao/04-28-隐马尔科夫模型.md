### 1. 隐马尔科夫模型HMM
- 定义
- 隐马尔科夫模型
  - 一种用于处理`序列数据`的概率模型；
  - 适用于隐藏状态不可直接观测，但可通过观测状态间接推断的场景
- `序列数据`
  - 数据点按时间、空间或其他逻辑顺序排列，且顺序不可随意调换，其中，数据之间的顺序关系包含重要信息
  - 特点
    - 有序性：有先后顺序，且不可随意调换
    - 依赖性：当前的数据点，可能依赖于前序或后序数据
    - 动态性：数据随着时间
  - 常见类型
    - 时间序列
    - 空间序列
    - 文本序列
    - 状态序列
- `核心作用：序列建模`
  - 隐藏状态与观测序列
    - 对隐藏状态、状态间转移概率、生成观测值概率，进行建模
  - 建模目标
    - 评估：计算观测序列的生成概率
    - 解码：推断最有可能的隐藏状态序列
    - 学习：从数据中学习模型参数
- 与分类任务的关系
  - 不是传统分类器，但可以间接支持分类任务
    - 对序列分类：将不同类别的数据，建模为不同的HMM
    - 对状态标签分类：将隐藏状态，视为类别标签
  - HMM与传统分类模型的区别
    - 输入数据：
      - HMM为序列数据，
      - 传统分类模型为独立数据点（数据之间无依赖关系）
    - 输出目标：
      - HMM：生成观测序列的概率；或隐藏状态序列
      - 传统分类模型：直接预测数据点的类别标签

### 2. 基本概念
- 隐藏状态：不可直接观测的状态
- 观察状态：可观测的、与隐藏状态相关的数据
- 两个独立性假设
  - 马尔科夫性：当前隐藏状态，仅依赖于前一状态，即，$P(z_t|z_{t-1})$；
  - 观测独立性：当前观测仅依赖当前隐藏状态，即，$P(x_t|z_t)$

### 3. 模型组成
- 初始概率分布 $π$：初始时刻，各`隐藏状态`的概率；
- `状态转移概率`矩阵 $A$：描述状态间的转移概率；
- `生成观察状态概率`矩阵 $B$：隐藏状态生成观察状态的概率

### 4. 三大核心问题
- 评估问题
  - 目标：计算给定模型及观测序列，观测序列的概率 $P(O|\lambda)$；求解（隐藏）状态序列，使得$P(O|\lambda)$最大
    - 模型：$\lambda$ = ($\pi$, $A$, $B$)
    - 观测序列：$O = \{o_1, o_2, ..., o_T\}$
      - 每个 $o_t$ 表示时刻 $t$ 的观测值
    - 隐藏状态序列：$I = \{i_1, i_2, ..., i_T\}$
      - 每个 $i_t$ 表示时刻 $t$ 的隐藏状态
  - 算法：前向算法（动态规划）
    - 通过递推，计算每个时刻的“前向概率”
- 学习问题
  - 目标：从观测序列中，学习模型参数（$\pi$、$A$、$B$）
  - 算法：Baum-Welch算法，通过迭代优化参数最大化 $P(O|\lambda)$
  - 步骤：E步计算期望，M步更新参数
- 解码问题
  - 找到最可能的隐藏状态序列
  - 算法：维特比算法（动态规划），记录每个时刻、每个状态的的最大概率路径，回溯得到最优序列

### 5. HMM算法应用
- 工具包
  - from hmmlearn import hmm
  - 