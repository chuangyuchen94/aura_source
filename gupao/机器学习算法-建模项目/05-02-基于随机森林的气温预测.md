### 0. 总结
- 对每一种算法，要进行总结：
  - 适合的任务：回归，分类
  - 分类：有监督，无监督，半监督
  - 特点
  - 评估指标
  - 评估方法
  - 具体的实现(工具包)
  - 参数：含义，调参的建议范围
  - 常用的场景
- 对任务的理解
  - 分类：有监督，无监督，半监督
  - 

### 1. 了解任务
- 气温预测：是连续值，是回归任务
- 要完成三项任务
  - 任务1：使用随机森林算法完成基本建模任务
    - 需要：处理数据、观察特征、完成建模、进行可视化展示分析
  - 任务2：观察数据量与特征个数对结果的影响
    - 在保证算法一致的前提下，加大数据个数，观察结果变换；
    - 重新考虑特征工程，引入新特征后，观察结果走势
  - 任务3：对随机森林算法进行调参，找到最合适的参数
    - 掌握机器学习中两种经典调参方法，对当前模型进行调节

### 2. 数据的观察与分析
- 针对每个特征与温度的关系，单独画图
- 特征的个数

### 3. 数据预处理
- One-Hot Encoding：独热编码
  - 对非数值型的数据进行预处理，转换成数值型的值
  - 工具包：
    - import pandas as pd
    - pd.get_dummies(data)
- 预处理完成后，将pandas数据转换成numpy数据

### 4. 训练集与测试集的切分
- from sklearn.model_selection import train_test_split

### 5. 建立一个基础的随机森林模型
- from sklearn.ensemble import RandomForestRegressor

### 6. 指定评估方法
- MAPE：平均绝对百分比误差
  - 越小越好

### 7. 可视化展示树
- 工具包：graphviz
- from sklearn.tree import export_graphviz
- import pydot

### 8. 限定参数值
- 树的个数
- 树的深度

### 9. 特征重要性
- 随机森林算法中，在训练完成后，针对每个特征，都有数值表示其重要性
- 进行展示
- 按重要性倒序排序

### 10. 用最重要的特征来试试
- 选择最重要的几个特征
- 重新训练模型
- 预测结果
- 评估结果
- 平衡预测结果质量与预测速度
  - 特征多，预测结果的质量相对高，但计算时的耗时多，速度相对慢；
  - 特征少，计算耗时相对少，速度相对快，但预测结果的质量相对低一些

### 11. 展示结果
- 将预测值与实际值画在一起

### 12. 加入新的数据与特征
- 特征增多，样本数据增多 
  - 增加数据，能提升结果的质量
  - 增加特征，能提升结果的质量
- 特征工程
  - 选特征很重要
- 选择重要特征：累加重要性 ≥ 95%
  - np.cumsum()

### 13. Pairplots
- import seaborn as sns
- sns.pairplot(df)

### 14. 调节新的参数
- 预剪枝
- 调参的思路
  - 有多个参数可选，每个参数有多个候选值 => 参数组合的可能性很多
- 方法1：随机选择（随机搜索）
  - 指定搜索的次数，从参数组合从随机挑选出指定次数的组合，找到其中表现最好的一个
  - 工具：
    - from sklearn.model_selection import RandomizedSearchCV
    - 方法
      - fit(X_train, y_train) # 用训练集的数据
    - 参数
      - estimator：指定算法模型
      - distributions：参数空间，是一个字典
      - n_iter：随机选择的次数
      - scoring：评估方法
      - cv：交叉验证的折数，一般设置为3
      - random_state：随机种子
      - n_jobs：多线程来跑这个程序，-1表示用所有的核心
    - 属性
      - best_params_：最好的参数组合
  - 步骤
    - 第1步，构造`参数空间`，由参数构成，并设定参数的取值范围
      - 对于随机森林
        - n_estimators：树的个数
        - max_features：最大特征的选择方式
        - max_depth：树的最大深度
        - min_samples_split：节点最小分裂所需样本个数
        - min_samples_leaf：叶子节点最小样本数
        - bootstrap：样本采样方法
      - 把以上参数做出一个参数空间（字典）
        - key是模型的实际参数的名称，value就是参数的取值
- 方法2：网格搜索（地毯式搜索）
  - 每种组合都测试一遍，找到表现最好的那一个，但耗时大
  - 改进策略：在随机搜索的结果的基础上，进行微调
  - 工具：
    - from sklearn.model_selection import GridSearchCV
  - 步骤：
    - 第1步，构建网格
      - 对每个参数的随机搜索的结果，进行上下取值，构成新的参数空间
    - 第2步，选择基本算法模型
    - 第3步，构建、执行网格搜索
    - 第4步，得到当前的最好的参数组合
    - 第5步，重复第1步~第4步，直到得到自己满意的结果

### 15. 总结
- 参数空间非常重要
- 先随机，后网格
- 调参的方法有很多，比如，贝叶斯优化，即，每一个优化都是在不断积累经验
  - Hyperopt工具包
- 