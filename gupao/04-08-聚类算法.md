### 1. K-MEANS算法
- 聚类概念
  - 无监督学习：事先没有提供标签，由模型自己训练、进行发现
  - 聚类：将相似的数据点划分为同一组，一组称为一个聚类
  - K-MEANS：迭代优化质心位置，以将数据划分为K个簇
    - 难点
      - 如何评估：评估聚类的质量
      - 如何调参：K值的选择
- 核心概念
  - `K值`：预先指定
    - 需要预先确定K值，即，要划分的簇的个数。直接影响结果的质量
    - 用“肘部法则”观察不同的K值对应的损失函数的拐点
  - `质心`：每个簇的中心点
    - 通过计算簇内所有数据点各维度的均值来求得
    - 例如：二维数据点簇，C = {(1, 2), (3, 4), (5, 6)}
      - 质心坐标：$(\frac{1+3+5}{3}, \frac{2+4+6}{3})=(3, 4)$
    - 动态更新：每次迭代后，质心坐标应根据最新的数据点簇来重新计算
  - `距离的度量`：常用，欧几里得距离，余弦相似度
    - `欧几里得距离`（需要先标准化；适用于数值型数据）：$$d(x, c) = \sqrt{(x_1 - c_1)^2 + (x_2 - c_2)^2 + ... + (x_n - c_n)^2}$$ 用矩阵表示： $$D^2=diag(XX^T)1_k^T+1_ndiag(CC^T)-2XX^T$$ 
      - $diag()$：提取矩阵对角线元素组成列向量
      - $1_k^T$：k个1组成的列向量
      - $1_n$：n个1组成的列向量
      - $X$：簇内的数据点
      - $C$：质心
    - `余弦相似度`（适合高维稀疏数据，需先对数据归一化）：$$d(x, c) = \frac{x· c}{||x||||c||}$$
  - `优化目标`：最小化每个数据点到其所属簇质心的距离之和 $$\min\sum_{i=1}^k\sum_{x\in C_i}dist(c_i, x)^2$$
    - 矩阵表示：$$
\min_{\mathbf{Z}, \mathbf{C}} \|\mathbf{X} - \mathbf{Z}\mathbf{C}\|_F^2
$$
      - Z：分配矩阵，$\mathbf{Z} \in \{0, 1\}^{n \times k}$，$Z_{ij}=1$表示样本$i$属于簇$j$，否则为0
      - $\|·\|_F$是矩阵的Frobenius范数，即所有元素平方和的平方根$\sqrt{\sum_{i,j}x_{ij}^2}$
  - `质心更新`：每次迭代后，质心坐标应根据最新的数据点簇来重新计算 $$C=(Z^TZ)^{-1}Z^TX$$

### 2. K-MEANS算法的标准工作流程
- 步骤1：初始化质心
  - 随机选择K个数据点，作为初始质心
  - 关键点：通过K-Means++优化算法，来选择初始质心
- 步骤2：分配数据点到最近的质心
  - 计算每个点与质心的距离，并选择距离最小的质心，作为最近的质心；
  - 形成当前的簇
  - 用欧几里得距离，或余弦相似度
- 步骤3：更新质心（质心不一定是数据点）
  - 基于每个当前的簇，重新计算质心坐标
- 步骤4：判断收敛
  - 检查质心是否不再显著变化，或者已经达到最大迭代次数
  - 停止条件：
    - 质心变化率小于阈值：$\|C_i^{new} - C_i^{old}\|<\epsilon-6$
    - 每个簇的样本点不再发生变化
    - 达到最大迭代次数
- 步骤5：迭代优化
  - 重复步骤2、步骤3、步骤4、直至达到停止条件
- 步骤6：输出结果

### 3. K_MEANS算法的优势及劣势
- 优势：
  - 简单、快速
  - 适用于常规数据集
- 劣势：
  - K值难确定
  - 复杂度与样本数量呈线性关系
  - 不适用于任意形状的簇

### 4. K-MEANS算法的实现
- 第1步：根据指定的K值
- 第2步：对数据进行预处理
  - 标准化
  - 归一化
- 第3步：初始化质心
  - 随机选择K个数据点，作为初始化质心，用K-Mean++算法来选择初始质心
    - 先选择第1个质心（随机选择一个数据点）
    - 后续初始质心的选择：以概率正比于已选质心的最小距离的平方 $$ P(x) = \frac{D(x)^2}{\sum_{x_i \in \text{Data}} D(x_i)^2} $$
      - $D(x)$：数据点到已选质心的最小距离。可能已经有不止一个已选质心，所以要在多个已选质心中，选择最小的一个
      - $D(x)^2$：距离的平方，用于放大远距离的数据点的影响
- 步骤4：分配数据点到其最近的质心
  - 计算每个数据点到每个质心的距离，取最小值，对应的质心为这个数据点的质心
    - 距离的计算：欧式距离
- 步骤5：更新质心
  - 计算每个簇的均值，作为新的质心
- 步骤6：判断收敛
  - 迭代停止条件：满足其一即可
    - 新质心到旧质心的变化率小于阈值
    - 已执行最大迭代次数
- 步骤7：若不满足停止条件，则重复执行步骤4/5/6
- 步骤8：输出结果
  - 结果：
    - 质心的坐标点
    - 簇的分配结果

### 5. DBSCAN算法
- 适用的场景：
  - 异常检测
- 优于K-MEANS算法
- 基本概念
- 