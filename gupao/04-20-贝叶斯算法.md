### 1. 贝叶斯简介
- 解决了“逆概”问题
  - 正向概率
    - 例：假设袋子里有N个白球、M个黑球，摸出黑球的概率
  - 逆向概率
    - 例：事先不知道袋子里黑白球的比例，摸出若干个球后，观察这些球的颜色后，对袋子里的黑白球比例做出推测
- 贝叶斯公式：$$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$

### 2. 模型比较理论
- `最大似然`：最符合观测数据的最优优势
  - 最符合观测数据（即P(D|h)最大的）
- 奥卡姆剃刀：P(h)较大的模型有较大的优势
  - 先验概率较大的模型，具有较大的优势
- 例：平面上的N个点
  - 可以分别用直线来拟合（模型1），也可以用二阶多项式来拟合（模型2），也可以用三阶多项式来拟合（模型3）；尤其是，可以用N-1阶多项式来完美的通过N个数据点
  - 用“奥卡姆剃刀”来解读：越是高阶的多项式越是不常见
- 例：垃圾邮件过滤实例
  - 假设：
    - D：表示垃圾邮件，由N个单词组成
    - h+：表示垃圾邮件
    - h0：表示正常邮件
  - 则
    - P(h+|D) = P(h+)*P(D|h+)/P(D)
    - P(h-|D) = P(h-)*P(D|h-)/P(D)
  - 计算过程
    - P(h+|D)和P(h-|D)是用来比较大小的，所以，两个式子的P(D)都可以约去不计
    - P(h+)和P(h-)，作为先验概率，只要计算一个邮件库里垃圾邮件和正常邮件的比例就可以求得
    - D里面有N个单词d1, d2, d3, ..., dn，所以
      - P(D|h+) = P(d1|h+) * P(d2|d1, h+) * P(d3|d2, d1, h+)*...
  - `朴素贝叶斯`：假设di与di-1是完全条件无关的，即，特征之间相互独立、互不影响
    - p(D|h+)进一步简化为P(d1|h+)*P(d2|h+)*P(d3|h+)*...
      - 对于P(d1|h+),P(d2|h+),P(d3|h+)...，只要统计di这个单词在垃圾邮件中出现的频率即可
- 例：拼写检查
- 问题：我们看到用户输入了一个不在字典中的单词，我们猜测：他真正想要输入的单词是什么？
- P(我们猜测他想输入的单词|他实际输入的单词)
- 贝叶斯定理很重要的一点：先验概率

### 3. 贝叶斯算法实现
- 垃圾邮件过滤实例
- 概述
  - D表示邮件，由N个单词组成
  - h+：垃圾邮件
  - h-：正常邮件
- 需要解决的两个问题：
  - 遇到出现的词语，既不在垃圾词组中，也不在正常词组中，则P(n|h+)为0，导致整个乘式为0；
  - 概率值每一个都很小，累乘后接近于0
- 步骤
  - 步骤1：预处理
    - 邮件数据读取
    - 分词
    - 将单词转换为小写
  - 步骤2：创建语料表
  - 步骤3：切分训练集、测试集
  - 步骤4：构建特征向量、标签
    - 统计词汇在正常邮件、垃圾邮件中出现的概率
  - 