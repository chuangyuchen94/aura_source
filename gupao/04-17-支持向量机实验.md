### 1. SVM带来的效果
- 工具：from sklearn.svm import SVC
  - 参数：
    - C：松弛因子
    - kernel：核函数
  - 属性：
    - coef_：权重参数（当核函数是"linear"时）
    - intercept_：偏执项
    - support_vectors_: 支持向量

### 2. 数据标准化的影响
- 拿到数据之后，第一件事就是要做标准化
- 工具：from sklearn.preprocessing import StandardScaler

### 3. 软间隔的作用
- 目的：防止过拟合
  - 异常点、离群点
- C值
  - 使用较高的C值，分类器会减少误分类，最终会有较小的间隔
  - 使用较小的C值，间隔会大很多，很多实例会出现在间隔之内

### 4. 非线性支持向量机


### 5. 核函数的作用：SVM中的核技巧
- 工具：from sklearn.svm import SVC
- 参数：
  - kernel
    - "rbf"：类似高斯核函数，几乎常用
    - "linear"：线性核函数
    - "poly"：多项式核函数
  - degree
    - kernel="poly"时，需要指定degree值
  - gamma
- 高斯核函数：利用相似度来变换特征
  - 径向基函数（RBF）公式：$$\phi\gamma(\mathbf{x}, {\ell}) = \exp \left( -\gamma \| \mathbf{x} - {\ell} \|^2 \right)$$
  - 当$\gamma$变小时，过拟合风险也会变小
  - 对每一个实例（样本数据点）创建一个地表，此时会将(m, n)的训练集转换成m*m的训练集
- SVM中利用了核函数的计算技巧，大大降低了计算复杂度
  - 增加$\gamma$，使高斯曲线变窄，因此每个实例的影响范围都较小：决策边界最终变得更不规则，在个别实例周围摆动，，过拟合风险会变大
  - 减少$\gamma$，使高斯曲线变宽，因此实例具有更大的影响范围，并且决策边界更加平滑，过拟合风险会变小
- 