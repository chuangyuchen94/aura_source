### 1. SVM：支持向量机
- 核心理念：选择间隔最大化的决策边界
  - 好的决策边界：尽可能的远离雷区
    - `超平面`：SVM的目标是找到一个超平面（二维是一条直线，三维是一个平面），能够将不同类别的数据分开
  - `支持向量（雷区）`：离决策边界最近的那些点
    - 决定了间隔的大小、边界的位置
- 包含：
  - 两类数据点：
    - 正例：标记为+1
    - 负例：标记为-1
    - 决策边界：一条直线、曲线或平面，取决于核函数
    - 间隔边界：两条平行于决策边界的虚线，穿过正负类的支持向量
    - 支持向量：位于间隔边界上的数据点
- `距离的计算`
  - `超平面方程`：$$w^Tx+b=0$$
    - $w$：超平面的法向量
    - $b$：偏置项
  - 超平面上的点
    - 若点$x_1$和$x_2$在超平面上，则满足$$w^Tx_1+b=0$$ $$w^Tx_2+b=0$$
    - 由此推出：$$w^T(x_1-x_2)=0$$，即向量$x_1-x_2$位于超平面内，且与法向量$w$正交（垂直）
    - 法向量：垂直于某个平面、直线或曲面的向量
  - `点到超平面的距离`：任意点$x_i$到该超平面的垂直投影长度 $$d(x_i, w)=\frac{|w^Tx_i+b|}{||w||}$$
    - 分母$||w||$：法向量的模长，用于归一化
    - 分子$|w^Tx_i+b|$：点到超平面的代数距离，符号（+1或-1）由特征类别决定
  - 间隔最大化：SVM的目标是最大化两类支持向量到超平面的最小距离
    - 优化问题转换为最小化$||w||$
- 数据标签的定义
  - SVM属于有监督学习，样本的类别由标签Y明确定义为+1或-1——二分类任务
  - `决策方程`：将特征空间划分为正负两类区域 $$y(x) = w^T \Phi(x) + b$$
    - $w$：超平面的法向量
    - $\Phi(x)$：对原始数据做非线性转换，从低维映射为高维，以解决线性不可分的问题
    - $b$：偏置项
  - 分类规则：由决策方程推导得出
    - 若$y(x_i)>0$，则预测$Y_i=+1$；
    - 若$y(x_i)<0$，则预测$Y_i=-1$；
    - 综合得：大于0保证了分类正确 $$Y_i·y(x_i)>0$$
- `优化的目标`
  - 目标：找到一个超平面，使得支持向量距离超平面的距离（间隔宽度）最远
  - 间隔：点到超平面的距离
  - 支持向量的定义：$$|w^T \Phi(x_i) + b|=1$$
  - 间隔宽度：$$|w^T \Phi(x_i) + b|+|w^T \Phi(x_j) + b|=2$$ 
    - i和j为支持向量
    - 间隔宽度进一步等于：$$\sum_{x \in S}^md(x_i, w)=\sum_{x \in S}^m{\frac{|w^T\Phi(x_i)+b|}{||w||}}=\frac{2}{||w||}$$ $S$为支持向量
  - 求间隔距离$argmax\sum_{x \in S}^md(x_i, w)$，约等于求$\frac{1}{||w||}$的最小值，带约束条件$y_i(w^T \Phi(x_i) + b)≥1$