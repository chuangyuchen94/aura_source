### 0. 写在前面：能用分类算法的，尽量就不用聚类算法
- 实在没有标签的，再用聚类算法

### 1. K-MEANS与DBSCAN算法
- 构造数据集
  - 工具：sklearn.datasets.make_blobs # 构建数据
- K-MEANS类
  - 工具：sklearn.cluster.KMeans # K-MEANS算法
  - 参数：
    - n_cluster：簇的个数
    - init：初始质心的方法
    - n_init: 运行初始质心方法的次数，并取最优
    - max_iter: 最大迭代次数
  - 方法
    - fit(X): 训练模型
    - fit_predict(X)：训练模型，并返回每个数据样本的聚类标签
    - transform(X)：计算X中每个样本到质心的距离
- 算法流程：K-MEANS每走一步，是什么样子 
- 不稳定的结果
  - 初始质心对结果的影响较大
- 图像分隔小例子
  - K-MEANS的数据集的维度：2维

### 2. 半监督问题解决方案
- 用于半监督学习的标签：
  - 标签值为典型数据的代表，可以理解为预先指定每个簇的中心点（或离中心点相当接近的数据点）
  - 预先用k-means算法把中心点（质心）找出来
- 方法1：找出典型的标签，进一步挑出标签代表的数据，用于LogisticRegression的训练
- 方法2：找出典型的标签，并将标签传播到同一簇的其他数据，用整体的数据进行训练
- 方法3：找出离每个质心最近的n个数据，将这些数据用于训练（对于方法1来说，n=1）
- 测试数据
  - from sklearn.datasets import load_digits

### 3. DBSCAN算法的使用
- 测试：构造数据集
  - from sklearn.datasets import make_moons
  - X, y = make_moons(n_samples=1000, noise=0.05, random_state=0)
- DBSCAN与K-MEANS的应用领域不同
  - DBSCAN：适用于发现任意形状
  - K-MEANS：适用于发现成堆的数据
- 工具: from sklearn.cluster import DBSCAN
  - 参数：
    - eps: 半径
    - min_samples: 半径内的样本个数
  - 属性：
    - labels_: 每个样本的聚类标签。-1表示离群点

### 4. 聚类评估方法
- 评估标准
  - sklearn.cluster.KMeans的属性：`inertia_` -- 所有样本到其最近的质心的欧式距离之和
  - 找到`最佳簇数`：找拐点
    - 随着k值的增大，评估值会越来越低
    - 找到拐点：在拐点之后，评估值的下降趋势变得不明显
- K-MEANS存在的问题
  - 评估指标的值小，并不一定就意味着分类的结果正确：评估指标只能用来参考
- 另外一个评估标准：`轮廓系数`
  - 由两个值组成：
    - $ai$ - 样本i的簇内不相似度：每个样本到其所属簇的其他样本的平均距离。
    - $bi$ - 样本i的簇间不相似度：每个样本到其他某簇$C_j$的所有样本的平均距离$b_{ij}$。$b_i=min{bi_{i1}, b_{i2}, ..., b_{ik}}$
  - $s_i = \frac{b_i - a_i}{max(a_i, b_i)}$
    - $s_i$越接近1，则说明样本i的聚类合理
    - $s_i$越接近-1，则说明样本i更应该分类到另外的簇
    - $s_i$近似为0，则说明样本i的在两个簇的边界上
  - 工具包：sklearn.metrics.silhouette_score