### 1. 隐马尔科夫模型HMM
- 定义
- 隐马尔科夫模型
  - 一种用于处理`序列数据`的概率模型；
  - 适用于隐藏状态不可直接观测，但可通过观测状态间接推断的场景
- `序列数据`
  - 数据点按时间、空间或其他逻辑顺序排列，且顺序不可随意调换，其中，数据之间的顺序关系包含重要信息
  - 特点
    - 有序性：有先后顺序，且不可随意调换
    - 依赖性：当前的数据点，可能依赖于前序或后序数据
    - 动态性：数据随着时间
  - 常见类型
    - 时间序列
    - 空间序列
    - 文本序列
    - 状态序列
- `核心作用：序列建模`
  - 隐藏状态与观测序列
    - 对隐藏状态、状态间转移概率、生成观测值概率，进行建模
  - 建模目标
    - 评估：计算观测序列的生成概率
    - 解码：推断最有可能的隐藏状态序列
    - 学习：从数据中学习模型参数
- 与分类任务的关系
  - 不是传统分类器，但可以间接支持分类任务
    - 对序列分类：将不同类别的数据，建模为不同的HMM
    - 对状态标签分类：将隐藏状态，视为类别标签
  - HMM与传统分类模型的区别
    - 输入数据：
      - HMM为序列数据，
      - 传统分类模型为独立数据点（数据之间无依赖关系）
    - 输出目标：
      - HMM：生成观测序列的概率；或隐藏状态序列
      - 传统分类模型：直接预测数据点的类别标签

### 2. 基本概念
- 隐藏状态：不可直接观测的状态
- 观察状态：可观测的、与隐藏状态相关的数据
- 两个独立性假设
  - 马尔科夫性：当前隐藏状态，仅依赖于前一状态，即，$P(z_t|z_{t-1})$；
  - 观测独立性：当前观测仅依赖当前隐藏状态，即，$P(x_t|z_t)$

### 3. 模型组成
- 初始概率分布 $π$：初始时刻，各`隐藏状态`的概率；
- `状态转移概率`矩阵 $A$：描述状态间的转移概率；
- `生成观察状态概率`矩阵 $B$：隐藏状态生成观察状态的概率

### 4. 三大核心问题（已知其中2个，求解第3个）
- 问题1：评估问题（已知 $\lambda$ 和 $O$，求 $P(O|\lambda)$ ）
  - 目标：计算给定模型 $\lambda$ 及观测序列 $O$ ，观测序列的概率 $P(O|\lambda)$；求解（隐藏）状态序列，使得 $P(O|\lambda)$ 最大
    - 模型：$\lambda$ = ($\pi$, $A$, $B$)
    - 观测序列：$O = \{o_1, o_2, ..., o_T\}$
      - 每个 $o_t$ 表示时刻 $t$ 的观测值
    - 隐藏状态序列：$I = \{i_1, i_2, ..., i_T\}$
      - 每个 $i_t$ 表示时刻 $t$ 的隐藏状态
  - 算法：`前向算法`（动态规划）
    - 通过递推，计算每个时刻的“前向概率”
- 问题2：学习问题（已知 $O$，求 $\lambda$ ）
  - 目标：从观测序列中 $O$（通常隐藏序列 $I$ 不可观测、是未知的），学习模型参数 $\lambda(\pi, A, B)$
  - 算法：`Baum-Welch算法`，通过迭代优化参数最大化 $P(O|\lambda)$
  - 步骤：E步计算期望，M步更新参数
- 问题3：解码问题（已知 $\lambda$ 和 $O$，求 $I$ ）
  - 找到最可能的隐藏状态序列 $I$
  - 算法：`维特比算法`（动态规划），记录每个时刻、每个状态的的最大概率路径，回溯得到最优序列

### 5. HMM算法应用
- 工具包
  - from hmmlearn import hmm
- 官方文档：https://hmmlearn.readthedocs.io/en/latest/

### 6. 中文分词任务
- 定义观测和状态
  - 观测：看到的句子
  - 状态：对句子中的字的划分的状态
- 定义状态
  - B: 词开头；M：词中；E：词结尾；S：独字词
- 定义任务
  - 拿到一句话，找到其隐藏状态：每个字的状态

### 7. 模型的算法实现--学习问题（已知 $O$ ）
- 步骤1：初始化状态
  - 确保状态之和为1
- 步骤2：初始化转移概率、观测概率
  - 初始化方法：
    - 方法1：有先验知识，则统计先验知识的频率作为概率
    - 方法2：随机生成后，对每行的概率值进行归一化，确保每行的概率值之和为1
- 步骤3：E步（计算期望）
  - 目的：计算在当前参数模型下，隐藏状态的后验概率和相关期望值
  - 主要计算两个重要的概率
    - 前向概率 $\alpha_{t(i)}$：在时刻 $t$ 观测到的前 $t$ 个观测值、其处于状态 $i$ 的概率
    - 后向概率 $\beta_{t(i)}$：在时刻 $t$ 处于状态 $i$ 的条件下，从时刻 $t+1$ 观测到的后续观测值的生成概率
  - 计算期望统计值
    - $P(O|\lambda) = \sum_{i=1}^N\alpha_T(i)$
    - 状态占用概率 $\gamma_t(i) = \frac{\alpha_{t(i)} · \beta_{t(i)}}{P(O|\lambda)}$
    - 状态转移期望 $\xi_t(i, j) = \frac{\alpha_{t(i)} · A_{ij} · B_j(o_{t+1}) · \beta_{t+1}(j)}{P(O|\lambda)}$
  - 1）计算前向概率
    - $\alpha_1 = \pi \odot B_{o_1}$ （$\odot：逐元素乘法$）
    - $\alpha_t = (\alpha_{t-1} \cdot A) \odot B{o_t}$
  - 2）计算后向概率
    - 终止时刻：$\beta_T = 1$ (全1向量)
    - 递推公式：$\beta_t = A \cdot (B_{o_{t+1}} \odot \beta_{t+1})$
  - 3）计算状态占用概率：用于更新初始概率、观测概率
  - 4）计算状态转移期望：用于更新转移概率
- 步骤4：M步（更新参数），使得观测序列的似然概率最大
  - 目标：利用E步的期望统计值，更新模型参数（拉格朗日乘数法）
  - 1）更新初始概率 $\pi_i = \gamma_1(i)$
  - 2）更新转移概率
  - 3）更新观测概率

### 8. 模型的算法实现--评估问题（已知 $\lambda$ 和 $O$，求 $P(O|\lambda)$ ）
- 